\chapter{Introduction}

\section{Motivation}
One of the keys factors that has driven transformation of computing industry in the last years is the perception of computing utilities as an ordinary property, which can be easily accessed and adjusted to a specific needs. That point of view resulted in profusion of different services, often collectively referred as a cloud computing. Similarly to services common to traditional markets, customers expect them to be accessible on demand and in easy manner, while paying only for the consumed goods. Furthermore, customers are interested in a given service provider only when it is eligible to guarantee appropriate quality of service.

The particular service providers that are addressed by this paper are the ones that supply users with an application execution platform, what is widely known as providing Platform-as-a-Service. In that case, a customer is an entity that has developed application and is eager to deploy it on an application platform that is able to fulfil his specific requirements, both in terms of quality and cost.

Having customer requirements in mind, it is crucial that service provider is able to adapt itself to meet them. For example, such adaptation can be triggered by a sudden spike in resource demand and may result in provisioning additional application platforms. However, due to the complexity of a system under consideration, there are different levels where adaptation is possible:
\begin{itemize}
	\item user application
	\item application platform
	\item infrastructure
\end{itemize} 
What is more, the fact that single service provider is constrained by his finite amount of resources poses a risk that it may not be able to serve customer all the time. Consequently, it is expected that adaptation at a service provider level is also possible, i.e. provider can offload some traffic to a different provider, as long as it satisfies a customer.

While autonomic computing has a long history, it has not been directly applied to a multi-layered problem that exists in a cloud computing environment. Especially, the research area at the last layer, which sizes across different service providers, is new. Although, architecture known as InterCloud investigates problem of cooperation and negotiation at cloud level, it neither has been implemented nor presented in context of autonomic system.

\textit{business potential - dobry hajs, wymagania do QoS, lista produktow i ze nie maja pierdolniecia}

\section{Contributions}
The main contributions of this dissertation are as follows:
\begin{itemize}
  \item A proposal of an architecture of federated cloud computing environment, which is based on and can be viewed as a simplified version of \emph{InterCloud}
  \item The notion of considering each service model as an autonomic system
  \item The implementation of the proposed architecture using OpenNebula technology stack
\end{itemize}

\section{Impact}
We hope that the ideas contained in this work be beneficial to the OpenNebula ecosystem as they provide insights into the ways the following features can be implemented:
\begin{itemize}
  \item autoscaling capabilities
  \item virtual machines provisioning
  \item managing of a group of virtual machines which forms a logical entity
\end{itemize}
What is more, we believe that our successful attempt to implement a simplified variant of an InterCloud architecture will cause its gain in interest and popularity. And finally, the idea of representing each level of an autoscaling subsystem as an autonomic one can be thought-provoking for cloud computing scientists.

\section{Thesis structure}
